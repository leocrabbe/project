{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of Trumps Tweets\n",
    "### by: Ginue(Justin) Han and Leo Crabbe\n",
    "\n",
    "\n",
    "## Research Questions\n",
    "Donald Trump’s Twitter presence was one of the key factors in his 2016 presidential campaign, and remains one of the most infamous facets of his presidency. This project will analyse his Twitter output to find potential patterns in the way he posts on the website.\n",
    "1. What are the top 20 words he uses in his tweets?\n",
    "We are trying to compute the most words he uses excluding words like “I”, “the”, etc. We want to see if the words he uses have positive or negative meanings. \n",
    "2. Is there a correlation between his tweets and approval rating?\n",
    "We are trying to compute a correlation between his tweets and approval rating. We want to see if his controversial tweets affect his approval rating\n",
    "3. When does he tweet the most?\n",
    "We are trying to find a correlation between the time of day and how likely Trump is to tweet.\n",
    "4. How often does he use superlatives?\n",
    "We are trying to compute how frequently he uses words like “best”, “greatest”, etc, and whether his use of them has changed over time. More specifically did he begin using them more during his bid for the presidency?\n",
    "5. What tweets have the most reach?\n",
    "We are trying to compute what tweets have the most reach based on the number of retweets they have, and seeing if there’s a correlation between the impact of the tweet and it’s length/sentence structure. \n",
    "\n",
    "## Motivation and Background\n",
    "\n",
    "In this age, social media plays a huge role in getting information to people in a fast and easy way as well as communicating your thoughts. Many popular people use social media and attract millions of followers who want to keep up to date on what they are doing and saying which can have a major impact on their followers and their image depending on what they say. President Trump is one of the first presidents of the USA to utilize social media(Twitter) to this extent sending out several tweets almost everyday garnering thousands of comments, retweets, and likes. Some of these tweets are considered to be incredibly controversial with his comments on his opposition, the wall, etc. His tweets have a major influence on his followers and we want to see what topics he tweets about, what tweets are the most controversial, correlation between his tweets and approval rating, and crime rates. It is important to track his tweets because of his views that tend to misinform and incite hate among his followers. By tracking what he tweets and what has the greatest impact can help us pinpoint what issues are seemingly most important and controversial in America as well as seeing if his tweets are causing a greater divide. \n",
    "\n",
    "## Dataset\n",
    "\n",
    "For the Trump approval ratings data, the data was collected through polls and compiled together in a csv document. It includes the dates the polls were taken from 2017 to 2019, the high and low ratings for approval and disapproval, and then the averages for approval and disapproval. \n",
    "https://github.com/fivethirtyeight/data/tree/master/trump-approval-ratings\n",
    "\n",
    "Here is a .csv file of Donald Trump’s tweets, complete with time of posting and amount of likes/retweets.\n",
    "https://raw.githubusercontent.com/sashaperigo/Trump-Tweets/master/data.csv\n",
    "\n",
    "## Methodology\n",
    "\n",
    "For this project, while each question has its own individual approach, there is a general process that connects them. For the first three questions we are going to be analyzing individual Tweets and comparing them with some variable that differs between the three questions. For the first question we want to analyze the individual words of each tweet by turning every tweet into a list or dictionary and keeping count of how many times individual words appear. With this information we want to see the type of connotation that are associated with each word.For question Two we want to see if there is a correlation with between Trump’s tweet and the nations perception of him using presidential approval ratings. We want to compare the general time frame of a tweet and see if there is a significant change in his approval rating. For the third question we want to see when he is most likely to tweet by extracting the time a tweet was published and keeping track how often a tweet is likely to occur at a given time. For this one we are trying to see if there is a range of times, say between 2am-3am, when he is most likely to post on his social media. For this question we are not analyzing the content of the tweets themselves but rather the time when one could expect a tweet to most likely occur.\n",
    "    \n",
    "Question Four has the same general process of question one with the except that we will only be looking for certain words to appear rather than seeing how many times different words appear. We will make a dictionary or list (unsure at this time) with certain keywords already included and using function to count the number of times those words have appeared in his tweets similar to question one. The difference we want to observe between this question and question is one whether there has been a change in usage over time. We want to compare his usage of these words with his time in the presidency to see if the frequency of their usage has increased or decreased with time. Question 5 explores the possibility of the structure/length of a tweet influencing the overall reach of his tweets. We want to see if there is a correlation between how many characters his tweets contain and how many people interact with his tweet by “liking” the tweet. For this question we have considered the possibility of no correlation existing. Question Six will be approached by making a graph of the general trend in hate crimes across a few years. We will examine the overall numbers of hate crimes perpetrated as stated by the FBI for several years under 2 different presidencies. For this question we are aware that the general trend for hate crimes has been increasing over the years, likely due to an increasing and diversifying population, we want to see if there is a larger increase than what should be expected under Trump’s presidency. To do this we will create two graphs using the statistics for Obama’s presidency (or some other president or more than one president)  and one for Trump’s presidency and then compare the slope of the graphs with each other. This question represents a unique challenge because although the FBI database goes back several presidents, the newest report for 2018 or 2019 are not yet available for Trump so we only have 2 possible data points so far which greatly sway the slope of a graph compared to other presidents. A possible solution that we are considering is using only the first two years of two different presidents and comparing those to Trump’s first two years as president. \n",
    "\n",
    "## Workplan\n",
    "\n",
    "This project is comprised of 6 smaller questions rather than one big one, so we will be assigning 2 questions to each member of the group.\n",
    "\n",
    "The work for each question will involve a few common steps:\n",
    "1. __Extract the data:__ The main file we will be using is a large .csv file containing all Trump’s tweets paired with data on how they were received on Twitter. Some of our questions require only the tweets’ contents, some require contents in addition to number of retweets, favourites, etc. Therefore we’ll have to extract a different set of strings for each question using file IO commands.\n",
    "\n",
    "2. __Analyse the data:__ In the case of question 1, for example, this will involve creating a dictionary containing every word in the tweets (as keys) paired with the number of times they are used, and then iteratively appending the top 20 words to a list. A similar dictionary method will be used for question 3, but with times of the day and number of tweets as the pairing. For question 4 words ending in -est will be extracted and counted, and again the most common ones will be appended to a list (the words will have to be combed through to avoid outlier non-superlatives like ‘guest’ and also to include words like ‘least’ which don’t end in -est. The other 3 questions are correlation questions, each testing whether there’s a correlation between 2 variables. In each case a scatterplot of them will be plotted, and the Pearson coefficient for the plot will be calculated.\n",
    "\n",
    "3.  __Interpret the data:__ In the case of the correlation questions, this means interpreting the coefficient to conclude whether a correlation exists, and in the case of the other questions this means looking at the trends and offering a hypothesis as to why they exist.  \n",
    "\n",
    "4.  __Presenting the data:__ After the relevant data is gathered and conclusions have been drawn the data/conclusions should be presented in an easy to read fashion in a Jupyter Notebook/PDF file. Each individual will format their own questions’ section in the report.Throughout this assignment we will be consulting each other about our respective questions if we encounter problems. We have a shared Google Doc where we’ll be able to paste and edit each-other’s code. We won’t be pair coding as we will each have 2 questions to work on independently, though if we do find ours difficult we’ll meet and work on it together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/trump_approval/approval_topline.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e657e6b60821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mdates_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/trump_approval/approval_topline.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mratings_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapproval_ratings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/trump_approval/approval_topline.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e657e6b60821>\u001b[0m in \u001b[0;36mdate\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mopen_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mcsv_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#stores indexes of columns you want values from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/trump_approval/approval_topline.csv'"
     ]
    }
   ],
   "source": [
    "def approval_ratings(file):\n",
    "    open_file = open(file)\n",
    "    csv_file = csv.reader(open_file)\n",
    "    #stores indexes of columns you want values from\n",
    "    approval_column_index = 0\n",
    "    #stores values from desired columns\n",
    "    approval_values=[]\n",
    "    #loop through the rows in the csv file\n",
    "    for row in csv_file:\n",
    "        #if the indexes var is empty, loop through the elements in the row and \n",
    "        #if its == approve/disapprove_estimate, then add the index number to \n",
    "        #the approvae/disapprove index var.\n",
    "        if approval_column_index == 0:\n",
    "            for i in range(len(row)):\n",
    "                if \"approve_estimate\" == row[i]:\n",
    "                    approval_column_index = i\n",
    "        else:\n",
    "            approval_values.append(float(row[approval_column_index]))\n",
    "    return list(reversed(approval_values))\n",
    "    \n",
    "\n",
    "def date(file):\n",
    "    open_file = open(file)\n",
    "    csv_file = csv.reader(open_file)\n",
    "    #stores indexes of columns you want values from\n",
    "    first_col = True\n",
    "    #stores values from desired columns\n",
    "    dates=[]\n",
    "    #loop through the rows in the csv file\n",
    "    for row in csv_file:\n",
    "        if first_col == True:\n",
    "            first_col = False\n",
    "        else:\n",
    "            if \"/\" in row[2][0:2]:\n",
    "                dates.append(row[2][0])\n",
    "            else:\n",
    "                dates.append(row[2][0:2])\n",
    "            dates[len(dates)-1] += row[2][-5:]\n",
    "    return list(reversed(dates))\n",
    "\n",
    "dates_list = date(\"data/trump_approval/approval_topline.csv\")\n",
    "ratings_list = approval_ratings(\"data/trump_approval/approval_topline.csv\")\n",
    "\n",
    "def average_per_month(ratings, dates):\n",
    "    ratings_per_month = {}\n",
    "    counter = {}\n",
    "    for i in range(len(dates)):\n",
    "        if dates[i] not in ratings_per_month.keys():\n",
    "            ratings_per_month[dates[i]] = ratings[i]\n",
    "            counter[dates[i]] = 1\n",
    "        else:\n",
    "            ratings_per_month[dates[i]] += ratings[i]\n",
    "            counter[dates[i]] += 1\n",
    "    for key in ratings_per_month.keys():\n",
    "        ratings_per_month[key] = ratings_per_month[key]/counter[key]\n",
    "    return ratings_per_month\n",
    "    \n",
    "approval_ratings_data = average_per_month(ratings_list, dates_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/trump_approval/tweets.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4e40c1be67c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfavorite_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mfavorite_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/trump_approval/tweets.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtweet_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-4e40c1be67c5>\u001b[0m in \u001b[0;36mfavorite_count\u001b[0;34m(file, d)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfavorite_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mopen_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcsv_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfavorite_column_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#stores values from desired columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/trump_approval/tweets.csv'"
     ]
    }
   ],
   "source": [
    "def favorite_count(file,d='\\t'):\n",
    "    open_file = open(file,'r', encoding='utf8', errors='ignore')\n",
    "    csv_file = csv.reader(open_file)\n",
    "    favorite_column_index = 0\n",
    "    #stores values from desired columns\n",
    "    favorite_values=[]\n",
    "    #loop through the rows in the csv file\n",
    "    for row in csv_file:\n",
    "        #if the indexes var is empty, loop through the elements in the row and \n",
    "        #if its == approve/disapprove_estimate, then add the index number to \n",
    "        #the approvae/disapprove index var.\n",
    "        if favorite_column_index == 0:\n",
    "            for i in range(len(row)):\n",
    "                if \"favorite_count\" == row[i]:\n",
    "                    favorite_column_index = i\n",
    "        else:\n",
    "            favorite_values.append(int(row[favorite_column_index]))\n",
    "    return list(reversed(favorite_values))\n",
    "\n",
    "favorite_count(\"data/trump_approval/tweets.csv\")\n",
    "\n",
    "def tweet_date(file):\n",
    "    open_file = open(file,'r', encoding='utf8', errors='ignore')\n",
    "    csv_file = csv.reader(open_file)\n",
    "    #stores indexes of columns you want values from\n",
    "    first_col = True\n",
    "    #stores values from desired columns\n",
    "    dates=[]\n",
    "    #loop through the rows in the csv file\n",
    "    for row in csv_file:\n",
    "        if first_col == True:\n",
    "            first_col = False\n",
    "        else:\n",
    "            dates.append(row[3])\n",
    "            dates[len(dates)-1] += \"/\"\n",
    "            dates[len(dates)-1] += row[4]\n",
    "    return list(reversed(dates))\n",
    "\n",
    "dates_tweet_list = tweet_date(\"data/trump_approval/tweets.csv\")\n",
    "favorites_tweet_list = favorite_count(\"data/trump_approval/tweets.csv\")\n",
    "tweet_favorite_data = average_per_month(favorites_tweet_list, dates_tweet_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_line_plot(dict1, dict2):\n",
    "    '''Creates two different lines graphs that share the same x axis but have \n",
    "    different y axis. takes in dict1 and dict2 as parameters and use them to\n",
    "    plot the lines. '''\n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    #sets x and y label. color= sets color of y label\n",
    "    ax1.set_xlabel(\"Date\")\n",
    "    ax1.set_ylabel(\"Average Approval Rating\", color=color)\n",
    "    #plot dict1.keys() as x axis and dict1.values() as line. sets color of line\n",
    "    ax1.plot(dict1.keys(),dict1.values(), color=color)\n",
    "    #rotates x tick labels\n",
    "    plt.xticks(rotation=90)\n",
    "    #colors the ax1 label\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    #create a 2nd axes that shares same x axis as ax1\n",
    "    ax2 = ax1.twinx()\n",
    "    color2 = 'tab:blue'\n",
    "    #sets ylabel name and color\n",
    "    ax2.set_ylabel(\"Average Tweet Favorites\", color=color2)\n",
    "    #plots dict2\n",
    "    ax2.plot(dict2.values(), color=color2)\n",
    "    #colors ylabel\n",
    "    ax2.tick_params(axis='y', labelcolor=color2)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "############LEO CODE#########################\n",
    "\n",
    "def read_csv(path):\n",
    "    \"\"\"Reads the CSV file at path, and returns a list of rows from the file.\n",
    "\n",
    "    Parameters:\n",
    "        path: path to a CSV file. \n",
    "\n",
    "    Returns:\n",
    "        list of dictionaries: Each dictionary maps the columns of the CSV file\n",
    "        to the values found in one row of the CSV file. Although this function \n",
    "        will work for any csv file, for our purposes, depending on the contents\n",
    "        of the CSV file, this will typically be a list of *ElectionDataRow*s or\n",
    "        a list of *PollDataRow*s (or a list of electoral college data rows).\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    csv_file = open(path)\n",
    "    for row in csv.DictReader(csv_file):\n",
    "        output.append(row)\n",
    "    csv_file.close()    \n",
    "    return output\n",
    "\n",
    "allwords = []\n",
    "for line in read_csv('data.csv'):\n",
    "    for word in line['Text'].split():\n",
    "        allwords.append(word)\n",
    "\n",
    "\n",
    "# If i don't adjust for common words, the top most commonly used words would all be prepositions or verbs like \"do\"\n",
    "# so I downloaded a text file of the 10000 most commonly used english words and add an if statement that ensures\n",
    "# that if a word in a tweet belongs tho this list of words it won't be counted\n",
    "\n",
    "common_words = []\n",
    "\n",
    "myFile = open(\"commonwords.txt\")\n",
    "for line in myFile:\n",
    "    word = str(line)\n",
    "    word = word.replace(\"\\n\",\"\")\n",
    "    common_words.append(word)\n",
    "myFile.close()    \n",
    "\n",
    "\n",
    "words = []\n",
    "\n",
    "for word in allwords:\n",
    "    word = word.replace(\".\", \"\") # we dont want the code to count \"thanks\" and \"thanks.\" separately\n",
    "    word = word.replace(\"!\", \"\") # or \"thanks!\" and \"thanks\"\n",
    "    word = word.replace('\"', \"\") # or \" thanks\" \" and \" thanks \"\n",
    "    if word.lower() == word:\n",
    "          pass\n",
    "    elif word.lower() in common_words:\n",
    "        pass\n",
    "    elif word[0] == \"@\":         # we don't want to consider twitter mentions (eg @HillaryClinton)\n",
    "        pass\n",
    "    else:\n",
    "        words.append(word.lower())\n",
    "\n",
    "counts = {}         \n",
    "for i in words:           # this iterates through the words and counts how many times they appear in the list\n",
    "    if i in counts:\n",
    "        counts[i] += 1\n",
    "    else:\n",
    "        counts[i] = 1\n",
    "\n",
    "# here i make new dictiorary that is just counts{} but with the keys and values switched \n",
    "# i do this because it's easier for sort the keys in increasing order here\n",
    "        \n",
    "nucounts = {}      \n",
    "for i in counts:\n",
    "    nucounts[counts[i]] = i\n",
    "\n",
    "def common_words(dictionary):\n",
    "    for j in range(-20,0):           \n",
    "        i = sorted(dictionary)[j]\n",
    "        print(dictionary[i], \"was said\", i , \"times\")\n",
    "\n",
    "\n",
    "\n",
    "# for extraction of superlatives the method if almost the same as the common words one\n",
    "\n",
    "# the qualifier i'm using for superlatives is that their last 3 letters are \"est\" (with the exception of \"worst\")\n",
    "# this isn't perfect as there are a lot of words ending in 'est' that aren't superlatives but we'll just\n",
    "# have to ignore them\n",
    "\n",
    "superlatives = []\n",
    "for word in allwords:\n",
    "    if len(word) > 2:\n",
    "        if (word[-3], word[-2], word[-1]) == (\"e\",\"s\",\"t\"):  \n",
    "            superlatives.append(word.lower())\n",
    "        elif word == \"worst\":\n",
    "            superlatives.append(word.lower())\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "supercounts = {}\n",
    "for i in superlatives:\n",
    "    if i in supercounts:\n",
    "        supercounts[i] += 1\n",
    "    else:\n",
    "        supercounts[i] = 1\n",
    "\n",
    "nuucounts = {}\n",
    "for i in supercounts:\n",
    "    nuucounts[supercounts[i]] = i\n",
    "\n",
    "def superlatives(dictionary):\n",
    "    \n",
    "    for j in range(-20,0):\n",
    "        i = sorted(dictionary)[j]\n",
    "        print(dictionary[i], \"was said\", i , \"times\")\n",
    "\n",
    "\n",
    "    \n",
    "times = {}\n",
    "for line in read_csv('data.csv'):\n",
    "    hour = line['Date'][-8] + line['Date'][-7]\n",
    "    if hour in times:\n",
    "        times[hour] += 1\n",
    "    else:\n",
    "        times[hour] = 1\n",
    "\n",
    "    \n",
    "sort_times = {}\n",
    "for i in sorted(times):\n",
    "    sort_times[i] = times[i]\n",
    "    \n",
    "\n",
    "\n",
    "# Generate a normal distribution, center at x=0 and y=5\n",
    "frequency = list(sort_times.keys())\n",
    "time_of_day = list(sort_times.values())\n",
    "\n",
    "def histogram_plot(x,y):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_xlabel('Time of Day')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(r'Histogram of times of day that Trump tweets')\n",
    "\n",
    "\n",
    "    ax.bar(x, y, width= 0.8, align= 'edge')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "#### Question 1: \n",
    "\n",
    "\"I\", \"Donald\", and \"Trump\" were all in the top 4 most common words in the president's tweets. Given what some would call his egotistical persona this result is perhaps unsurprising. Also included were \"Obama\", \"China\", \"Hillary\", \"Obamacare\", \"#makeamericagreatagain\" and \"#trump2016\". These were of course all buzzwords and catchphrases from his 2016 election campaign. Interestingly \"#celebapprentice\" and \"apprentice\" show up, meaning Trump has tweeted about his reality show more times than the \"wall\" or any one politician except Obama/Hillary (\"Ted\" or \"Cruz\", for example, are absent from the list).\n",
    "\n",
    "#### Question 2:\n",
    "\n",
    "\n",
    "\n",
    "#### Question 3:\n",
    "\n",
    "There is a definite peak in Trump's tweeting between 2 and 5pm. What's surprising is that there's a sharp drop after that, and then a steady increase in tweeting frequency until 11pm, where there is a smaller drop. One could assume this is often Trump's bedtime. A hypothesis for explaining the 2-5 peak is perhaps that this is the time of day when the Trump typically has some downtime, and therefore can tweet freely.\n",
    "\n",
    "#### Question 4:\n",
    "\n",
    "#### Question 5:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations was said 228 times\n",
      "not was said 248 times\n",
      "#celebapprentice was said 284 times\n",
      "american was said 311 times\n",
      "obamacare was said 313 times\n",
      "apprentice was said 341 times\n",
      "china was said 395 times\n",
      "hillary was said 417 times\n",
      "#makeamericagreatagain was said 435 times\n",
      "i'm was said 501 times\n",
      "via was said 529 times\n",
      "mr was said 580 times\n",
      "#trump2016 was said 668 times\n",
      "president was said 787 times\n",
      "america was said 980 times\n",
      "obama was said 1083 times\n",
      "donald was said 1395 times\n",
      "thanks was said 1671 times\n",
      "trump was said 3546 times\n",
      "i was said 5857 times\n",
      "\n",
      "coldest was said 9 times\n",
      "request was said 11 times\n",
      "lowest was said 13 times\n",
      "test was said 17 times\n",
      "smartest was said 18 times\n",
      "finest was said 21 times\n",
      "dumbest was said 23 times\n",
      "largest was said 26 times\n",
      "latest was said 34 times\n",
      "honest was said 37 times\n",
      "rest was said 38 times\n",
      "interest was said 39 times\n",
      "guest was said 40 times\n",
      "dishonest was said 59 times\n",
      "highest was said 63 times\n",
      "west was said 66 times\n",
      "biggest was said 96 times\n",
      "worst was said 107 times\n",
      "greatest was said 145 times\n",
      "best was said 713 times\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "common_words(nucounts)\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "#two_line_plot(approval_ratings_data, tweet_favorite_data)\n",
    "\n",
    "\n",
    "\n",
    "histogram_plot(frequency, time_of_day)\n",
    "\n",
    "\n",
    "\n",
    "superlatives(nuucounts)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Plan Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration\n",
    "Our partner Jose Campos dropped the class so only the two of us worked on this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mREADME.md\u001b[m\u001b[m*       \u001b[31mcommonwords.txt\u001b[m\u001b[m* \u001b[31mdata.csv\u001b[m\u001b[m*        \u001b[31mtrump_tweets.py\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
